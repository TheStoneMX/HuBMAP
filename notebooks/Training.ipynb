{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to train models.\n",
    "  - Use the `DEBUG` parameter to launch the code in debug mode (single fold, no logging)\n",
    "  - Specify the training parameters in the `Config` class. Feel free to experiment with the parameters, here are the main ones :\n",
    "    - `tile_size` : Tile size\n",
    "    - `reduce_factor` : Downscaling factor\n",
    "    - `on_spot_sampling` : Probability to accept a random tile with in the dataset\n",
    "    - `overlap_factor` : Tile overlapping during inference\n",
    "    - `selected_folds` : Folds to run computations for.\n",
    "    - `encoder` : Encoder as defined in [Segmentation Models PyTorch](https://github.com/qubvel/segmentation_models.pytorch)\n",
    "    - `decoder` : Decoders from [Segmentation Models PyTorch](https://github.com/qubvel/segmentation_models.pytorch)\n",
    "    - `num_classes` : Number of classes. Keep it at 2 to use the healthy and unhealthy classes\n",
    "    - `loss` : Loss function. We use the BCE but the lovasz is also interesting\n",
    "    - `optimizer` : Optimizer name\n",
    "    - `batch_size` : Training batch size, adapt the `BATCH_SIZES` dictionary to your gpu\n",
    "    - `val_bs` : Validation batch size\n",
    "    - `epochs` : Number of training epochs\n",
    "    - `iter_per_epoch` : Number of tiles to use per epoch\n",
    "    - `lr` : Learning rate. Will be decayed linearly\n",
    "    - `warmup_prop` : Proportion of steps to use for learning rate warmup\n",
    "    - `mix_proba` : Probability to apply MixUp with\n",
    "    - `mix_alpha` : Alpha parameter for MixUp\n",
    "    - `use_pl`: Probability to sample a tile from the pseudo-labeled images\n",
    "    - `use_external`: Probability to sample a tile from the external images\n",
    "    - `pl_path`: Path to pseudo labels generated by `notebooks/Inference_test.ipynb`\n",
    "    - `extra_path` : Path to extra labels generated by `notebooks/Json to Mask.ipynb`\n",
    "    - `rle_path` : Path to train labels downscaled by `notebooks/Image downscaling.ipynb`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sys.path.append(\"../code/\")\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = \"1,0\"\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.main import k_fold\n",
    "\n",
    "from utils.logger import (\n",
    "    prepare_log_folder,\n",
    "    save_config,\n",
    "    create_logger,\n",
    "    update_overall_logs,\n",
    ")\n",
    "\n",
    "from params import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZES = {\n",
    "    \"resnet18\": 64,\n",
    "    \"resnet34\": 32,\n",
    "    \"resnext50_32x4d\": 32,\n",
    "    \"se_resnext50_32x4d\": 32,\n",
    "    \"efficientnet-b0\": 32,\n",
    "    \"efficientnet-b1\": 32,\n",
    "    \"efficientnet-b2\": 32,\n",
    "    \"efficientnet-b3\": 16,\n",
    "    \"efficientnet-b4\": 16,\n",
    "    \"efficientnet-b5\": 16,\n",
    "    \"efficientnet-b6\": 8,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"\n",
    "    Parameters used for training\n",
    "    \"\"\"\n",
    "    # General\n",
    "    seed = 42\n",
    "    verbose = 1\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    save_weights = True\n",
    "\n",
    "    # Images\n",
    "    tile_size = 512\n",
    "    reduce_factor = 2\n",
    "    on_spot_sampling = 0.9\n",
    "    overlap_factor = 1.5\n",
    "\n",
    "    img_dir = DATA_PATH + f\"train_{tile_size}_red_{reduce_factor}\"\n",
    "    mask_dir = DATA_PATH + f\"masks_{tile_size}_red_{reduce_factor}\"\n",
    "\n",
    "    # k-fold\n",
    "    cv_column = \"5fold\"\n",
    "    random_state = 0\n",
    "    selected_folds = [0, 1, 2, 3, 4]\n",
    "\n",
    "    # Model\n",
    "    encoder = \"efficientnet-b1\"  # \"resnet18\" \"resnext50_32x4d\", \"resnet34\", \"efficientnet-b5\"\n",
    "    decoder = \"Unet\"  # \"Unet\", \"DeepLabV3Plus\"\n",
    "    encoder_weights = \"imagenet\"\n",
    "    num_classes = 2\n",
    "\n",
    "    # Training\n",
    "    loss = \"BCEWithLogitsLoss\"  # \"lovasz\"\n",
    "    activation = \"none\" if loss == \"lovasz\" else \"sigmoid\"\n",
    "\n",
    "    optimizer = \"Adam\"\n",
    "\n",
    "    batch_size = BATCH_SIZES[encoder]\n",
    "\n",
    "    if tile_size == 512:\n",
    "        batch_size = batch_size // 2\n",
    "\n",
    "    if batch_size >= 32:\n",
    "        epochs = 50 \n",
    "    elif batch_size >= 16:\n",
    "        epochs = 40\n",
    "    elif batch_size >= 6:\n",
    "        epochs = 30\n",
    "    else:\n",
    "        epochs = 25\n",
    "    val_bs = batch_size * 2\n",
    "    \n",
    "    iter_per_epoch = 5000\n",
    "    lr = 1e-3\n",
    "    warmup_prop = 0.05\n",
    "\n",
    "    first_epoch_eval = 0\n",
    "\n",
    "    mix_proba = 0\n",
    "    mix_alpha = 0.4\n",
    "    if mix_proba > 0:\n",
    "        epochs *= 3\n",
    "\n",
    "    use_pl = 0.15\n",
    "    use_external = 0.2\n",
    "\n",
    "    pl_path = \"../logs/2021-05-01/2/\"  \n",
    "    extra_path = [\n",
    "        \"../input/train_extra.csv\",  # Class healthy\n",
    "        \"../input/train_extra_onlyfc.csv\"  # Class unhealthy\n",
    "    ]\n",
    "    rle_path = [\n",
    "        f\"../input/train_{reduce_factor}_fix.csv\",  # Class healthy\n",
    "        f\"../input/train_{reduce_factor}_onlyfc.csv\",  # Class unhealthy\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "log_folder = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not DEBUG:\n",
    "    log_folder = prepare_log_folder(LOG_PATH)\n",
    "    print(f\"Logging results to {log_folder}\")\n",
    "    config_df = save_config(Config, log_folder + \"config.json\")\n",
    "    create_logger(directory=log_folder, name=\"logs.txt\")\n",
    "\n",
    "metrics = k_fold(Config, log_folder=log_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
